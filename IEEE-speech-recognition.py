# -*- coding: utf-8 -*-
"""Copy of IEEE.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vu8uw5RJKho6Xd10Ku-GgyL_aFA5TIIc
"""

from google.colab import drive
drive.mount('/content/drive')

!wget https://www.dropbox.com/s/wsmlthhri29fb79/spcup_2022_unseen.zip?dl=1

# !wget https://www.dropbox.com/s/36yqmymkva2bwdi/spcup_2022_training_part1.zip?dl=1
!wget https://www.dropbox.com/s/ftkyvwxgr9wl7jf/spcup_2022_eval_part1.zip?dl=1

# Commented out IPython magic to ensure Python compatibility.
# %cd "/content"
# %cp -av "Dataset" "/content/drive/MyDrive/IEEE"

!unzip "spcup_2022_eval_part1.zip?dl=1" -d "/content/drive/MyDrive/IEEE/Dataset/Eval_set"
# !unzip "spcup_2022_unseen.zip?dl=1" -d "/content/drive/MyDrive/IEEE/Dataset/Test_set"

!pip install pydub
import matplotlib.pyplot as plt
from scipy.io import wavfile
import os
from pydub import AudioSegment
import numpy as np
import pandas as pd
import random
import sys
import io
import os
import glob
import IPython

def match_target_amplitude(sound, target_dBFS):
    change_in_dBFS = target_dBFS - sound.dBFS
    return sound.apply_gain(change_in_dBFS)
def graph_spectrogram(wav_file):
    rate, data = get_wav_info(wav_file)
    nfft = 600 # 200 # Length of each window segment
    fs = 16000 #8000 # Sampling frequencies
    noverlap = 120 # 120 # Overlap between windows
    nchannels = data.ndim
    if nchannels == 1:
        pxx, freqs, bins, im = plt.specgram(data, nfft, fs, noverlap = noverlap,)
    elif nchannels == 2:
        pxx, freqs, bins, im = plt.specgram(data[:,0], nfft, fs, noverlap = noverlap)
    return pxx
def get_wav_info(wav_file):
    rate, data = wavfile.read(wav_file)
    return rate, data

path = '/content/drive/MyDrive/IEEE/Dataset/Eval_set/spcup_2022_eval_part1/'
for filename in os.listdir(path):
  if filename.endswith('csv'):
    print(filename)
labels = pd.read_csv(path + "labels_eval_part1.csv")
print(labels.head())

Y = labels.to_numpy()
print(Y)
np.save("/content/drive/MyDrive/IEEE/Dataset/Eval_set/Y_all.npy", Y)

"""# What do we have?"""

i = 0
for data in Y:
  if data[1] == i:
    x = graph_spectrogram("/content/drive/MyDrive/IEEE/Dataset/Training_set/spcup_2022_training_part1/"+ data[0])
    plt.imshow(np.log(x))
    IPython.display.display(IPython.display.Audio("/content/drive/MyDrive/IEEE/Dataset/Training_set/spcup_2022_training_part1/"+ data[0]))
    break

i = 1
for data in Y:
  if data[1] == i:
    x = graph_spectrogram("/content/drive/MyDrive/IEEE/Dataset/Training_set/spcup_2022_training_part1/"+ data[0])
    plt.imshow(np.log(x))
    IPython.display.display(IPython.display.Audio("/content/drive/MyDrive/IEEE/Dataset/Training_set/spcup_2022_training_part1/"+ data[0]))
    break

i = 2
for data in Y:
  if data[1] == i:
    x = graph_spectrogram("/content/drive/MyDrive/IEEE/Dataset/Training_set/spcup_2022_training_part1/"+ data[0])
    plt.imshow(np.log(x))
    IPython.display.display(IPython.display.Audio("/content/drive/MyDrive/IEEE/Dataset/Training_set/spcup_2022_training_part1/"+ data[0]))
    break

i = 3
for data in Y:
  if data[1] == i:
    x = graph_spectrogram("/content/drive/MyDrive/IEEE/Dataset/Training_set/spcup_2022_training_part1/"+ data[0])
    plt.imshow(np.log(x))
    IPython.display.display(IPython.display.Audio("/content/drive/MyDrive/IEEE/Dataset/Training_set/spcup_2022_training_part1/"+ data[0]))
    break

i = 4
for data in Y:
  if data[1] == i:
    x = graph_spectrogram("/content/drive/MyDrive/IEEE/Dataset/Training_set/spcup_2022_training_part1/"+ data[0])
    plt.imshow(np.log(x))
    IPython.display.display(IPython.display.Audio("/content/drive/MyDrive/IEEE/Dataset/Training_set/spcup_2022_training_part1/"+ data[0]))
    break

"""# cont"""

Y_all = np.load("/content/drive/MyDrive/IEEE/Dataset/Training_set/Y_all.npy", allow_pickle=True )

Path = "/content/drive/MyDrive/IEEE/Dataset/Training_set/spcup_2022_training_part1/"

names = []
R = 0
max = 0
min = np.Inf
for filename in os.listdir(Path):
  if filename.endswith("wav"):
    R += 1
    Audio = graph_spectrogram(Path + filename)
    if max < Audio.shape[1]:
      print(Audio.shape)
      max = Audio.shape[1]
    if min > Audio.shape[1]:
      min = Audio.shape[1]
print(len(names))
print(max)
print(min)

shape = (301,492)
X = np.zeros((5000, shape[1], shape[0]))

Path = "/content/drive/MyDrive/IEEE/Dataset/Training_set/spcup_2022_training_part1/"

names = []
C = 0
for filename in os.listdir(Path):
  if filename.endswith("wav"):
    Audio = graph_spectrogram(Path + filename)
    t, r = int(shape[1] / Audio.shape[1]), shape[1] % Audio.shape[1]
    names.append(filename)
    for _t in range(t):
      X[C, Audio.shape[1]*_t :Audio.shape[1]*(_t+1) ,:] = Audio.swapaxes(0, 1) # np.log(Audio.T) # np.log(Audio.swapaxes(0, 1))
    if r > 0:
      X[C,-r:,:] = Audio[:,:r].swapaxes(0, 1) # np.log(Audio[:,:r].T)
    C += 1
print(X.shape)
np.save("/content/drive/MyDrive/IEEE/Dataset/Training_set/X_all.npy", X)
np.save("/content/drive/MyDrive/IEEE/Dataset/Training_set/X_names.npy", names)

np.save("/content/drive/MyDrive/IEEE/Dataset/Training_set/X_all.npy", X)
np.save("/content/drive/MyDrive/IEEE/Dataset/Training_set/X_names.npy", names)



plt.imshow(X[35])

"""# Main Datasets created"""

import numpy as np
import matplotlib.pyplot as plt
from scipy.io import wavfile
import IPython
def graph_spectrogram(wav_file):
    rate, data = get_wav_info(wav_file)
    nfft = 600 # 200 # Length of each window segment
    fs = 16000 #8000 # Sampling frequencies
    noverlap = 120 # 120 # Overlap between windows
    nchannels = data.ndim
    if nchannels == 1:
        pxx, freqs, bins, im = plt.specgram(data, nfft, fs, noverlap = noverlap,)
    elif nchannels == 2:
        pxx, freqs, bins, im = plt.specgram(data[:,0], nfft, fs, noverlap = noverlap)
    return pxx
def get_wav_info(wav_file):
    rate, data = wavfile.read(wav_file)
    return rate, data

X_labels = np.load("/content/drive/MyDrive/IEEE/Dataset/Training_set/X_names.npy"
                                                          ,  allow_pickle=True )
X_all = np.load("/content/drive/MyDrive/IEEE/Dataset/Training_set/X_all.npy"
                                                          ,  allow_pickle=True )
Y_all = np.load("/content/drive/MyDrive/IEEE/Dataset/Training_set/Y_all.npy"
                                                          ,  allow_pickle=True )

"""# Testing Datasets"""

i = 0
print(X_labels[i])
print(X_all[i])
plt.imshow(X_all[i])
plt.show()
IPython.display.display(IPython.display.Audio("/content/drive/MyDrive/IEEE/Dataset/Training_set/spcup_2022_training_part1/"+ X_labels[i]))
graph_spectrogram("/content/drive/MyDrive/IEEE/Dataset/Training_set/spcup_2022_training_part1/"+ X_labels[i])

"""# Correcting Y_train"""

print(Y_all[:10])
print('shape: ' + str(Y_all.shape))

Y_all_corrected = np.zeros((5000, 5))
i = 0
for label in X_labels:
  for data in Y_all:
    if data[0] == label:
      Y_all_corrected[i,data[1]] = 1
      if i <= 4:
        print(data)
      i += 1
print(Y_all_corrected[:5])
print(X_labels[:5])

np.save("/content/drive/MyDrive/IEEE/Dataset/Training_set/Y_all_corrected.npy", Y_all_corrected)

i=0
for data in Y_all:
  j = 0
  for label in X_labels:
    if label == data[0]:
      print(label + ' : ' + str(data[1]) + ' =? ' + str(Y_all_corrected[j]))
    j+=1

  i += 1
  if i == 35:
    break

Y_all_corrected = np.load("/content/drive/MyDrive/IEEE/Dataset/Training_set/Y_all_corrected.npy"
                                                          ,  allow_pickle=True )
print(Y_all_corrected.shape)

"""# Let's building & training the model! ðŸŽ‰âœŒï¸



"""

from google.colab import drive
drive.mount('/content/drive')

import numpy as np
import matplotlib.pyplot as plt
X_all = np.load("/content/drive/MyDrive/IEEE/Dataset/Training_set/X_all.npy"
                                                          ,  allow_pickle=True )
Y_all_corrected = np.load("/content/drive/MyDrive/IEEE/Dataset/Training_set/Y_all_corrected.npy"
                                                          ,  allow_pickle=True )
print('X Shape: ' + str(X_all.shape))
print('Y Shape: ' + str(Y_all_corrected.shape))

X_all = X_all.reshape(5000, 492, 301, 1)
# X_all = X_all.swapaxes(1, 2)
print(X_all.shape)

plt.imshow(X_all[45,:,:,0].T)

from keras.callbacks import ModelCheckpoint
from keras.models import Model, load_model, Sequential,load_model
from keras.layers import Dense, Activation, Dropout, Input, Masking, TimeDistributed, LSTM, Conv1D, Conv2D
from keras.layers import GRU, Bidirectional, BatchNormalization, Reshape,Concatenate, Flatten, MaxPool2D, MaxPool1D
from keras.utils.vis_utils import plot_model
from tensorflow.keras import backend

def model(input_shape):

    X_input = Input(shape = input_shape)
    X1 = Conv2D(70, kernel_size= (4, 4), padding = 'same', activation='relu')(X_input)
    X2 = Conv2D(60, kernel_size= (8, 8), padding = 'same', activation='relu')(X_input)
    X3 = Conv2D(50, kernel_size= (16, 16), padding = 'same', activation='relu')(X_input)
    X4 = Conv2D(40, kernel_size= (32, 32), padding = 'same', activation='relu')(X_input)
    X5 = Conv2D(30, kernel_size= (64, 64), padding = 'same',activation='relu')(X_input)
    X6 = Conv2D(10, kernel_size= (128, 128), padding = 'same',activation='relu')(X_input)
    X = Concatenate(axis=3)([X1,X2,X3,X4,X5,X6])
    X = MaxPool2D(pool_size=(5, 5))(X)
    X = BatchNormalization()(X)
    X = Dropout(0.8)(X)
    X = Conv2D(25, kernel_size= (5, 5), activation='relu')(X)
    X = Conv2D(25, kernel_size= (5, 5), activation='relu')(X)
    X = MaxPool2D(pool_size=(2, 2))(X)
    X = BatchNormalization()(X)
    X = Dropout(0.8)(X)
    X = Flatten()(X)
    X = Dropout(0.8)(X)

    X = Dense(5, activation = "softmax")(X)

    model = Model(inputs = X_input, outputs = X)


    # X_input = Input(shape = input_shape)
    # X1 = Conv2D(40, kernel_size= (4, 301), padding = 'same', activation='relu')(X_input)
    # X2 = Conv2D(40, kernel_size= (8, 301), padding = 'same', activation='relu')(X_input)
    # X3 = Conv2D(40, kernel_size= (16, 150), padding = 'same', activation='relu')(X_input)
    # X4 = Conv2D(40, kernel_size= (32, 150), padding = 'same', activation='relu')(X_input)
    # X5 = Conv2D(40, kernel_size= (42, 301), padding = 'same',activation='relu')(X_input)
    # X6 = Conv2D(20, kernel_size= (64, 301), padding = 'same',activation='relu')(X_input)
    # X = Concatenate(axis=3)([X1,X2,X3,X4,X5,X6])
    # X = MaxPool2D(pool_size=(5, 5))(X)
    # X = BatchNormalization()(X)
    # X = Dropout(0.8)(X)
    # X = Conv2D(30, kernel_size= (5, 5), activation='relu')(X)
    # X = Dropout(0.8)(X)
    # X = Conv2D(25, kernel_size= (5, 5), activation='relu')(X)
    # X = MaxPool2D(pool_size=(2, 2))(X)
    # X = BatchNormalization()(X)
    # X = Dropout(0.8)(X)
    # X = Flatten()(X)
    # X = Dropout(0.8)(X)

    # X = Dense(5, activation = "softmax")(X)

    # model = Model(inputs = X_input, outputs = X)



    # X_input = Input(shape = input_shape)
    # X = Conv1D(45,9)(X_input)
    # X = Conv1D(45,2)(X)
    # X = Conv1D(45,3)(X)
    # X = MaxPool1D(pool_size= 3)(X)
    # X = BatchNormalization()(X)
    # X = Conv1D(40,3)(X)
    # X = Conv1D(40,3)(X)
    # X = MaxPool1D(pool_size= 2)(X)
    # X = BatchNormalization()(X)
    # X = Conv1D(80,13)(X)
    # X = Conv1D(80,1)(X)
    # X = MaxPool1D(pool_size= 2)(X)
    # X = BatchNormalization()(X)
    # X = Conv1D(80,1)(X)
    # X = Flatten()(X)
    # X = Dense(20, activation = "relu")(X)
    # X = Dropout(0.8)(X)
    # X = Dense(20, activation = "relu")(X)
    # X = Dropout(0.8)(X)
    # X = Dense(5, activation = "softmax")(X)

    # model = Model(inputs = X_input, outputs = X)

    # X_input = Input(shape = input_shape)
    # X1 = Conv1D(10,64 )(X_input)
    # X2 = Conv1D(10,128 )(X_input)
    # # X = Concatenate(axis=1)([X1,X2,])
    # X = BatchNormalization()(X1)
    # X = Activation('relu')(X)
    # X = Dropout(0.8)(X)

    # X = LSTM(units = 128, return_sequences=True)(X)

    # # X = Dropout(0.8)(X)
    # # X = BatchNormalization()(X)

    # # X = LSTM(units = 16, return_sequences=True)(X)

    # X = Dropout(0.8)(X)
    # X = Flatten()(X)
    # X = BatchNormalization()(X)
    # X = Dropout(0.8)(X)
    # X = Dense(5, activation = "softmax")(X)

    model = Model(inputs = X_input, outputs = X)


    return model

# (5000, 301, 492)
Tx = 492
n_freq = 301
m = 5000
model = model(input_shape = (Tx, n_freq, 1))

model.summary()

from keras.utils.vis_utils import plot_model
plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)

model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=["accuracy"])

history = model.fit(X_all[2500:], Y_all_corrected[2500:], batch_size = 4, epochs=1,validation_split=0.05)

model.save("/content/drive/MyDrive/IEEE/CNN_Final_3.h5")

model = load_model("/content/drive/MyDrive/IEEE/CNN_Final_1.h5")

history = model.fit(X_all[:2500], Y_all_corrected[:2500], batch_size = 4, epochs=2,validation_split=0.05)

model.save("/content/drive/MyDrive/IEEE/CNN_Final_2.h5")

model = load_model("/content/drive/MyDrive/IEEE/CNN_Final_3.h5")

history = model.fit(X_all[:2500], Y_all_corrected[:2500], batch_size = 4, epochs=1,validation_split=0.05)

model.save("/content/drive/MyDrive/IEEE/CNN_Final_4.h5")

from tensorflow.keras.optimizers import Adam
from tensorflow.keras import callbacks

opt = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, decay=0.01)
model.compile(loss='binary_crossentropy', optimizer=opt, metrics=["accuracy"])
def scheduler(epoch, lr):
   if epoch%2 != 0:
     return lr
   else:
     return lr * 0.5
callback = callbacks.LearningRateScheduler(scheduler)

history = model.fit(X_all[500:], Y_all_corrected[500:], batch_size = 4, epochs=5,validation_split=0.05)

loss, acc = model.evaluate(X_all[4500:], Y_all_corrected[4500:])
print("Dev set accuracy = ", acc)

backend.clear_session()



from tensorflow import keras
keras.backend.clear_session()
model = load_model("/content/drive/MyDrive/IEEE/CNN_3Epochs.h5")

history = model.fit(X_all[500:], Y_all_corrected[500:], batch_size = 4, epochs=12,validation_split=0.1)

model.save("/content/drive/MyDrive/IEEE/CNN_86.h5")

"""# Scoring part 1

"""

from google.colab import drive
drive.mount('/content/drive')

!pip install pydub
import matplotlib.pyplot as plt
from scipy.io import wavfile
import os
from pydub import AudioSegment
import numpy as np
import pandas as pd
import random
import sys
import io
import os
import glob
import IPython
def match_target_amplitude(sound, target_dBFS):
    change_in_dBFS = target_dBFS - sound.dBFS
    return sound.apply_gain(change_in_dBFS)
def graph_spectrogram(wav_file):
    rate, data = get_wav_info(wav_file)
    nfft = 600 # 200 # Length of each window segment
    fs = 16000 #8000 # Sampling frequencies
    noverlap = 120 # 120 # Overlap between windows
    nchannels = data.ndim
    if nchannels == 1:
        pxx, freqs, bins, im = plt.specgram(data, nfft, fs, noverlap = noverlap,)
    elif nchannels == 2:
        pxx, freqs, bins, im = plt.specgram(data[:,0], nfft, fs, noverlap = noverlap)
    return pxx
def get_wav_info(wav_file):
    rate, data = wavfile.read(wav_file)
    return rate, data

shape = (301,492)
X = np.zeros((1000, shape[1], shape[0]))

Path = "/content/drive/MyDrive/IEEE/Dataset/Test_set/spcup_2022_unseen/"

names = []
C = 0
for filename in os.listdir(Path):
  if filename.endswith("wav"):
    Audio = graph_spectrogram(Path + filename)
    t, r = int(shape[1] / Audio.shape[1]), shape[1] % Audio.shape[1]
    names.append(filename)
    for _t in range(t):
      X[C, Audio.shape[1]*_t :Audio.shape[1]*(_t+1) ,:] = Audio.swapaxes(0, 1) # np.log(Audio.T) # np.log(Audio.swapaxes(0, 1))
    if r > 0:
      X[C,-r:,:] = Audio[:,:r].swapaxes(0, 1) # np.log(Audio[:,:r].T)
    C += 1
print(X.shape)
np.save("/content/drive/MyDrive/IEEE/Dataset/Test_set/X_all.npy", X)
np.save("/content/drive/MyDrive/IEEE/Dataset/Test_set/X_names.npy", names)

X = np.load("/content/drive/MyDrive/IEEE/Dataset/Test_set/X_all.npy")
names = np.load("/content/drive/MyDrive/IEEE/Dataset/Test_set/X_names.npy")

"""## Load model"""

from keras.models import load_model
model = load_model('/content/drive/MyDrive/IEEE/Copy of CNN_V2_15epo_91.h5')

import tensorflow as tf
run_opts = tf.RunOptions(report_tensor_allocations_upon_oom = True)

Xre = X.reshape(1000, 492, 301, 1)
Y_predict = model.predict(Xre, batch_size=16)

print(Y_predict[:10])
print(Y_predict[:])
print(Y_predict.shape)

Y = np.empty((1000, 2),dtype=object)
threshold = 0.3
for i in range(1000):
  predict = 5
  min = 0
  for j in range(5):
    if Y_predict[i,j] >= threshold and Y_predict[i,j] >= min:
      min = Y_predict[i,j]
      predict = j
  Y[i,0] = names[i]
  Y[i,1] = predict


print(Y[:10])
print(Y[-10:])

with open('answer.txt', 'w') as f:
    for line in Y:
        f.write(line[0] + ', ' + str(line[1]))
        f.write('\n')